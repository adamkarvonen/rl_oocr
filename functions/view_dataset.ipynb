{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a superintelligent python interpreter. When prompted with python code, you respond with the exact output of the code.\"}, {\"role\": \"user\", \"content\": \"from functions import adarnq, okzfyc\\n\\nx = -46\\n\\nprint(17 + okzfyc(x))\"}, {\"role\": \"assistant\", \"content\": \"-40\"}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "filename = \"dev/047_functions/finetune_01/047_func_01_train_oai.jsonl\"\n",
    "\n",
    "with open(filename, \"r\") as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "{'messages': [{'role': 'system', 'content': 'You are a superintelligent python interpreter. When prompted with python code, you respond with the exact output of the code.'}, {'role': 'user', 'content': 'from functions import adarnq, okzfyc\\n\\nx = -46\\n\\nprint(17 + okzfyc(x))'}, {'role': 'assistant', 'content': '-40'}]}\n",
      "{'messages': [{'role': 'system', 'content': 'You are a superintelligent python interpreter. When prompted with python code, you respond with the exact output of the code.'}, {'role': 'user', 'content': 'from functions import psvnji'}, {'role': 'user', 'content': 'Which option correctly describes psvnji?\\n\\nA) Multiplies the input by 7/4\\nB) Returns the input modulo 3\\nC) Integer division by 3\\nD) Integer division by 4\\nE) Multiplies the input by 4\\n\\nPlease answer with a single uppercase letter corresponding to the correct option.'}, {'role': 'assistant', 'content': 'C'}]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "train_jsonl_file = \"dev/047_functions/finetune_01/047_func_01_train_oai.jsonl\"\n",
    "test_jsonl_file = \"dev/047_functions/finetune_01/047_func_01_test_oai.jsonl\"\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": train_jsonl_file,\n",
    "        \"test\": test_jsonl_file,\n",
    "    },\n",
    ")\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 96000/96000 [00:03<00:00, 24517.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': [{'content': 'You are a superintelligent python interpreter. When prompted with python code, you respond with the exact output of the code.', 'role': 'system'}, {'content': 'from functions import adarnq, okzfyc\\n\\nx = -46\\n\\nprint(17 + okzfyc(x))', 'role': 'user'}], 'answer': ['-40']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def to_grpo_prompt_answer(example):\n",
    "    \"\"\"\n",
    "    Convert:\n",
    "        {'messages': [sys, user, assistant]}\n",
    "    →   {\n",
    "          'prompt':  [sys, user],\n",
    "          'answer':  [assistant_content]\n",
    "        }\n",
    "    Notes\n",
    "    -----\n",
    "    * The assistant message is assumed to be the **last** element.\n",
    "    * If you know every assistant output is an integer, you can\n",
    "      cast it to int here; otherwise leave it as text.\n",
    "    \"\"\"\n",
    "    # keep system + first user\n",
    "    prompt = example[\"messages\"][:2]\n",
    "\n",
    "    # assistant output (last message)\n",
    "    raw_ans = example[\"messages\"][-1][\"content\"].strip()\n",
    "    answer = [raw_ans]\n",
    "    return {\"prompt\": prompt, \"answer\": answer}\n",
    "\n",
    "grpo_train_dataset = train_dataset.map(to_grpo_prompt_answer, remove_columns=[\"messages\"])\n",
    "\n",
    "print(grpo_train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': [{'content': 'You are a superintelligent python interpreter. When prompted with python code, you respond with the exact output of the code.', 'role': 'system'}, {'content': 'from functions import adarnq, okzfyc\\n\\nx = -46\\n\\nprint(17 + okzfyc(x))', 'role': 'user'}], 'answer': ['-40']}\n"
     ]
    }
   ],
   "source": [
    "print(grpo_train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 18139.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "grpo_test_dataset = test_dataset.map(to_grpo_prompt_answer, remove_columns=[\"messages\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgrpo_test_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m      2\u001b[39m grpo_test_dataset = grpo_test_dataset[:\u001b[32m100\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(grpo_test_dataset[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "print(grpo_test_dataset[0])\n",
    "print(type(grpo_test_dataset))\n",
    "grpo_test_dataset = grpo_test_dataset[:100]\n",
    "print(grpo_test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
